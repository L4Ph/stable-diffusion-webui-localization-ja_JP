{
  "API Key": {
    "key": "API Key",
    "tooltip": "ウェブAPIのセキュリティ確保に使用します。右の更新ボタンをクリックするとキーが(再)生成され、ゴミ箱アイコンをクリックするとキーが削除されます。"
  },
  "AdamW Weight Decay": {
    "key": "AdamW Weight の減衰",
    "tooltip": "AdamW Optimizerのウェイト減衰量。値が0に近い場合はトレーニングデータセットと密接に一致し、1に近い場合はより一般化しトレーニングデータセットから逸脱します。デフォルトは1e-2で、0.1より低い値を推奨されます。"
  },
  "Amount of time to pause between Epochs (s)": {
    "key": "エポック間で一時停止する時間(秒)",
    "tooltip": "「Nエポック後に一時停止」の値が0より大きい場合、訓練は数秒で一時停止されます。"
  },
  "Apply Horizontal Flip": {
    "key": "水平フリップを適用",
    "tooltip": "画像を水平方向に反転することをランダムに決定します。"
  },
  "Batch Size": {
    "key": "出力枚数",
    "tooltip": "訓練ステップごとに何枚の画像を処理しますか？"
  },
  "Cache Latents": {
    "key": "履歴のキャッシュ",
    "tooltip": "このボックスがチェックされている場合、レイテントはキャッシュされます。レイテントをキャッシュすると、より多くのVRAMを使用しますが、トレーニング速度は向上します。"
  },
  "Cancel": {
    "key": "取消",
    "tooltip": "トレーニングをキャンセル"
  },
  "Class Batch Size": {
    "key": "クラスのバッチサイズ",
    "tooltip": "一度に生成する分類/正規化画像の枚数。"
  },
  "Class Images Per Instance Image": {
    "key": "インスタンス画像あたりのクラス画像数",
    "tooltip": "インスタンス画像1枚につき、何枚の分類画像を使用するか。"
  },
  "Class Prompt": {
    "key": "クラスプロンプト",
    "tooltip": "分類/規則化画像を生成するためのプロンプトです。詳細は readme を参照してください。"
  },
  "Class Token": {
    "key": "クラストークン",
    "tooltip": "[filewords] を使用する場合、これは既存のプロンプトで使用/検索するクラス識別子です。単一の単語である必要があります。"
  },
  "Classification CFG Scale": {
    "key": "分類CFGスケール",
    "tooltip": "分類子／正則化画像に使用する分類子無しのガイダンススケール。"
  },
  "Classification Dataset Directory": {
    "key": "分類データセットディレクトリ",
    "tooltip": "分類/規則化画像を含むディレクトリ。"
  },
  "Classification Image Negative Prompt": {
    "key": "分類イメージのネガティブプロンプト",
    "tooltip": "クラスイメージを生成する際に使用するネガティブプロンプトです。空でも問題ありません。"
  },
  "Classification Steps": {
    "key": "分類のステップ",
    "tooltip": "分類画像/規則画像を生成する際に使用するステップ数。"
  },
  "Clip Skip": {
    "key": "Clip Skip",
    "tooltip": "テキストエンコーダの背面からのn番目のレイヤーの出力を使用 (n>=1)"
  },
  "Concepts List": {
    "key": "コンセプト一覧",
    "tooltip": "コンセプトJSONファイル、またはJSON文字列へのパス。"
  },
  "Constant/Linear Starting Factor": {
    "key": "定数/線形開始係数",
    "tooltip": "初期学習率を、main_lr*(この値)に設定します。対象となるLRが 0.00006で、この値を0.5に設定すると、スケジューラは0.000003で開始し、0.000006になるまで増加します。"
  },
  "Create From Hub": {
    "key": "ハブから作成",
    "tooltip": "ローカルチェックポイントを使用する代わりに、Huggingface.coからモデルをインポートします。ハブモデルには拡散ウエイトが含まれていなければなりません。クローンしたモデルでローカルフォルダを指定することができます。この場合、HFトークンは必要ありません。"
  },
  "Create Model": {
    "key": "モデルを作成",
    "tooltip": "新しいモデルを作成"
  },
  "Create": {
    "key": "作成",
    "tooltip": "さっさとモデルを作成してしまえ"
  },
  "Custom Model Name": {
    "key": "カスタムモデル名",
    "tooltip": ".ckptおよび.ptファイルを保存するときに使用するカスタム名です。サブディレクトリもこの名前になります。"
  },
  "Dataset Directory": {
    "key": "データセットディレクトリ",
    "tooltip": "学習用画像が格納されているディレクトリ"
  },
  "Debug Buckets": {
    "key": "バケットのデバッグ",
    "tooltip": "インスタンスとクラス・イメージを調べて、対応するクラス・イメージのないインスタンスイメージを報告します。"
  },
  "Discord Webhook": {
    "key": "DiscordをWebフォーク",
    "tooltip": "生成後にトレーニングサンプルをDiscordチャンネルに送信する"
  },
  "Existing Prompt Contents": {
    "key": "既存のプロンプトの内容",
    "tooltip": "[filewords] を使用すると、既存のプロンプトのフォーマット方法を文字列ビルダに指示します。"
  },
  "Extract EMA Weights": {
    "key": "EMAウェイトを抽出",
    "tooltip": "EMAの重みがモデルに保存されている場合、完全なUnetの代わりに、これらが抽出されます。トレーニングや微調整にはおそらく必要ありません。"
  },
  "Freeze CLIP Normalization Layers": {
    "key": "CLIP正規化レイヤーを固定",
    "tooltip": "トレーニング中にCLIPの正規化層を凍結させたままにします。高度な使い方で、モデルの性能や編集性が向上する可能性があります。"
  },
  "Generate Ckpt": {
    "key": "Ckptを生成",
    "tooltip": "現在のトレーニングレベルでチェックポイントを生成します。"
  },
  "Generate Class Images": {
    "key": "クラス画像の生成",
    "tooltip": "トレーニングなしで、トレーニング設定を用いて分類画像を作成する。"
  },
  "Generate Classification Images Using txt2img": {
    "key": "txt2imgを使用して分類画像を生成する。",
    "tooltip": "ソース チェックポイントと TXT2IMG を使用してクラスイメージを生成します。"
  },
  "Generate Classification Images to match Instance Resolutions": {
    "key": "インスタンスの解像度に合わせた分類画像の生成",
    "tooltip": "正方形のクラス画像を生成するのではなく、クラス画像と同じ解像度(複数可) で生成します。"
  },
  "Generate Graph": {
    "key": "グラフを作成する",
    "tooltip": "トレーニングログからグラフを生成し、トレーニング中の学習率と損失平均を示します。"
  },
  "Generate Sample Images": {
    "key": "サンプル画像を生成",
    "tooltip": "現在保存されているディフーザモデルを使用してサンプル画像を生成します。"
  },
  "Generate Samples": {
    "key": "サンプルを生成",
    "tooltip": "次のトレーニングエポックの後にサンプル生成を行う。"
  },
  "Generate a .ckpt file when saving during training.": {
    "key": "トレーニング中に保存するときに .ckpt ファイルを生成します。",
    "tooltip": "有効にすると、学習中に指定されたエポック間隔でチェックポイントが生成されます。これは、学習中に「重みを保存」ボタンを使って手動で生成することも制御します。"
  },
  "Generate a .ckpt file when training completes.": {
    "key": "トレーニングが完了したら.ckptファイルを生成します。",
    "tooltip": "有効にすると、トレーニングが正常に完了したときにチェックポイントが生成されます。"
  },
  "Generate a .ckpt file when training is cancelled.": {
    "key": "トレーニング中止時に.ckptファイルを生成する。",
    "tooltip": "有効にすると、ユーザーによってトレーニングがキャンセルされたときに、チェックポイントが生成されます。"
  },
  "Generate lora weights Generate lora weights for additional networks.": {
    "key": "追加のネットワークのためのloraの重みを生成します。",
    "tooltip": "有効にすると、追加ネットワークに対応したlora .safetensorsファイルがuiローラモデルディレクトリに生成されます。拡張ローラとは互換性がありません。"
  },
  "Generate lora weights when saving during training.": {
    "key": "トレーニング中に保存するときにloraの重みを生成します。",
    "tooltip": "有効にすると、トレーニング中に指定されたエポックごとにlora の.ptファイルが生成されます。 これは、「重みを保存」ボタンを手動でクリックしたときに.ptファイルを生成するかどうかにも影響します。"
  },
  "Generate lora weights when training completes.": {
    "key": "トレーニング完了時にlora の重みを生成します。",
    "tooltip": "有効にすると、トレーニング完了時にloraの .ptファイルが生成されます。"
  },
  "Generate lora weights when training is canceled.": {
    "key": "トレーニングキャンセル時にloraの重みを生成します。",
    "tooltip": "有効にすると、ユーザーによってトレーニングがキャンセルされたときに、loraの .ptファイルが生成されます。"
  },
  "Gradient Accumulation Steps": {
    "key": "勾配蓄積ステップ",
    "tooltip": "後方/更新パスを実行する前に蓄積する更新ステップの数。バッチサイズと同じになるようにする必要があります。"
  },
  "Gradient Checkpointing": {
    "key": "チェックポイントの傾度",
    "tooltip": "これは、特定の層の活性化をクリアし、後方パスで再計算することで、メモリ使用量を削減する手法です。実質的に、余分な計算時間とメモリ使用量の削減をトレードすることになります。"
  },
  "Graph Smoothing Steps": {
    "key": "グラフスムージングのステップ",
    "tooltip": "データをスムーズに表示するタイムスタンプの数。 値が小さいほど、より多くの情報を持つギザギザのグラフが多くなります。値が大きいと、よりきれいになりますが、若干精度が低くなります。"
  },
  "Half Model": {
    "key": "ハーフモデル",
    "tooltip": "これを有効にすると、fp16 精度のモデルが生成されます。品質損失を最小限に抑えながら、チェックポイントを小さくします。"
  },
  "HuggingFace Token": {
    "key": "HuggingFace Token",
    "tooltip": "ファイルのクローンに使用するhuggingfaceトークン。"
  },
  "Instance Prompt": {
    "key": "インスタンスプロンプト",
    "tooltip": "対象を記述するプロンプトが表示されます。 [Filewords] を使用して画像のファイル名/.txt を解析し、ここに既存のプロンプトを挿入します。"
  },
  "Instance Token": {
    "key": "インスタンストークン",
    "tooltip": "[filewords] を使用する場合、これは件名に固有のインスタンス識別子です。単一の単語である必要があります。"
  },
  "Learning Rate Scheduler": {
    "key": "学習率スケジューラー",
    "tooltip": "使用する学習率スケジューラ。すべてのスケジューラは、「定数」を除く提供されたウォームアップ時間を使用します。"
  },
  "Learning Rate Warmup Steps": {
    "key": "学習率ウォームアップのステップ",
    "tooltip": "LRスケジューラのウォームアップのステップ数。 LRは0から開始し、指定されたステップ数でこの値に増加します。"
  },
  "Learning Rate": {
    "key": "学習率",
    "tooltip": "モデルが学習する割合。デフォルトは2e-6です。"
  },
  "Load Settings": {
    "key": "設定の読み込み",
    "tooltip": "最後に保存したモデルのトレーニングパラメータをロードします。"
  },
  "Log Memory": {
    "key": "ログメモリ",
    "tooltip": "現在のGPUメモリ使用量を記録します。"
  },
  "Lora Model": {
    "key": "LoRA モデル",
    "tooltip": "LoRAモデルは、継続的な微調整やチェックポイント生成のためにロードします。"
  },
  "Use Lora Extended": {
    "key": "LoRA 拡張を使用",
    "tooltip": "LoRAモデルをレネットレイヤーで訓練します。これにより、品質と編集性が常に向上しますが、ファイルが大きくなります。"
  },
  "Lora UNET Rank": {
    "key": "LoRA UNET ランク",
    "tooltip": "LoRA UNETのランク(デフォルトは4) 。高い値＝ファイルサイズが大きくても品質が良い。低い値 = 低いファイルサイズで品質を犠牲にする。学習率はランクによって異なる働きをします。高精度(fp32) でロラを保存すると、ロラファイルが大きくなります。"
  },
  "Lora Text Encoder Rank": {
    "key": "LoRAテキストエンコーダーランク",
    "tooltip": "LoRAテキストエンコーダのランクです(デフォルト4) 。高い値＝ファイルサイズが大きくても品質が良い。低い値 = 低いファイルサイズで品質を犠牲にする。学習率は、ランクによって異なる働きをします。高精度(fp32) でLoRAを保存すると、LoRAファイルが大きくなります。"
  },
  "Lora Text Learning Rate": {
    "key": "LoRAテキスト学習率",
    "tooltip": "LoRAテキストエンコーダを訓練する学習率。正規の学習率は無視されます。"
  },
  "Lora Text Weight": {
    "key": "LoRA テキスト Weight",
    "tooltip": "チェックポイントを作成する際に、LoRA Weightを何％テキストエンコーダーに適用するか。"
  },
  "Lora UNET Learning Rate": {
    "key": "LoRAのUNET学習率",
    "tooltip": "LoRAユニットを学習させる際の学習速度です。通常の学習速度は無視されます。"
  },
  "Lora Weight": {
    "key": "LoRA Weight",
    "tooltip": "チェックポイントを作成する際に、ローラウェイトを何％ユニットに適用するか。"
  },
  "Max Resolution": {
    "key": "最大解像度",
    "tooltip": "入力画像の解像度。Bucketingを使用する場合は、画像バケットの最大サイズです。"
  },
  "Max Token Length": {
    "key": "最大トークンの長さ",
    "tooltip": "最大トークン長を指定します。おそらく75のままにしておいたほうがよいでしょう。"
  },
  "Memory Attention": {
    "key": "メモリに注意",
    "tooltip": "使用するメモリの種類です。'Xformers' は、flash_attleよりも優れたパフォーマンスを提供しますが、別のインストールが必要です。"
  },
  "Min Learning Rate": {
    "key": "最低学習率",
    "tooltip": "時間の経過とともに減少する最小学習率。"
  },
  "Mixed Precision": {
    "key": "混合された精度",
    "tooltip": "FP16またはBF16(利用可能な場合) を使用すると、メモリ性能が向上します。\"xformers\"を使用する場合は必須です。"
  },
  "Model Path": {
    "key": "モデルのパス",
    "tooltip": "Huggingface上のモデルのURL。'developer/model_name'の形式である必要があります。"
  },
  "Model": {
    "key": "モデル",
    "tooltip": "トレーニングするモデル"
  },
  "Name": {
    "key": "名前",
    "tooltip": "作成するモデルの名前"
  },
  "Number of Hard Resets": {
    "key": "ハードリセット数",
    "tooltip": "リスタートスケジューラによるコスパの良いLRのハードリセット回数"
  },
  "Number of Samples to Generate": {
    "key": "生成するサンプル数",
    "tooltip": "テーマごとに生成するサンプル数"
  },
  "Offset Noise": {
    "key": "ノイズをオフセット",
    "tooltip": "トレーニング中の明るさとコントラストをより詳細に学習できるようにします。値は効果の強さをコントロールし、0はそれを無効にします。"
  },
  "Pad Tokens": {
    "key": "パッドトークン",
    "tooltip": "入力画像のトークンの長さをこの値にパッドします。おそらくこれを行いたいと思うでしょう。"
  },
  "Pause After N Epochs": {
    "key": "N エポック後に一時停止",
    "tooltip": "指定された時間にトレーニングが一時停止された後のエポックの数です。GPUに休憩を与えたい場合に便利です。"
  },
  "Performance Wizard (WIP)": {
    "key": "パフォーマンスウィザード (WIP)",
    "tooltip": "VRAMの総量に応じたトレーニングパラメータの自動設定を試みます。まだ開発中です。"
  },
  "Polynomial Power": {
    "key": "多項式累乗",
    "tooltip": "多項スケジューラの力関係"
  },
  "Pretrained VAE Name or Path": {
    "key": "事前訓練済みのVAE名またはパス",
    "tooltip": "代替VAEを使用するには、VAEを表すpytorch_model.binを含むディレクトリへのパスを指定できます。"
  },
  "Preview Prompts": {
    "key": "プロンプトをプレビュー",
    "tooltip": "訓練に使用されるプロンプトデータの JSON 表現を生成する。"
  },
  "Prior Loss Weight": {
    "key": "正則化の損失の重み",
    "tooltip": "前にロスしたウェイト量"
  },
  "Sample CFG Scale": {
    "key": "サンプルCFGスケール",
    "tooltip": "プレビュー画像に使用する分類子無しのガイダンススケール。"
  },
  "Sample Image Prompt": {
    "key": "サンプル画像プロンプト:",
    "tooltip": "プレビュー画像の生成に使用するプロンプト。"
  },
  "Sample Negative Prompt": {
    "key": "ネガティブプロンプトのサンプル",
    "tooltip": "プレビュー画像の生成に使用するネガティブプロンプト。"
  },
  "Sample Prompt Template File": {
    "key": "サンプルプロンプトテンプレートファイル",
    "tooltip": "サンプルプロンプトに使用する txt ファイルへのパス。サンプル プロンプトにクラス トークンを挿入するには、 [filewords] または [name] を使用してください。"
  },
  "Sample Prompt": {
    "key": "サンプルプロンプト:",
    "tooltip": "サンプル イメージを生成するために使用するプロンプト"
  },
  "Sample Seed": {
    "key": "サンプルシード",
    "tooltip": "サンプル生成時に使用するシードです。毎回ランダムなシードを使用する場合は、-1 を設定します。"
  },
  "Sample Steps": {
    "key": "サンプルステップ",
    "tooltip": "分類画像/規則画像を生成する際に使用するステップ数。"
  },
  "Sanity Sample Prompt": {
    "key": "正常性確認用サンプルプロンプト",
    "tooltip": "モデルの忠実度を検証するために他のサンプルと一緒に作成される「ベースライン」イメージの生成に使用されるプロンプト。"
  },
  "Sanity Sample Seed": {
    "key": "正常性確認用サンプルシード値",
    "tooltip": "検証サンプル画像の生成時に使用するシード。-1 はサポートされていません。"
  },
  "Save Checkpoint to Subdirectory": {
    "key": "チェックポイントをサブディレクトリに保存",
    "tooltip": "有効にすると、チェックポイントは、選択したチェックポイントフォルダのサブディレクトリに保存されます。"
  },
  "Save Model Frequency (Epochs)": {
    "key": "モデルの頻度を保存 (エポック)",
    "tooltip": "N個のエポックごとにチェックポイントを保存する。"
  },
  "Save Model Frequency (Step)": {
    "key": "モデルの保存頻度 (ステップ)",
    "tooltip": "Nエポックごとにチェックポイントを保存します。バッチ数で割り切れる必要があります。"
  },
  "Save Preview(s) Frequency (Epochs)": {
    "key": "プレビュー保存頻度 (エポック数)",
    "tooltip": "N エポックごとにプレビュー画像を生成します。"
  },
  "Save Preview(s) Frequency (Step)": {
    "key": "プレビュー保存頻度 (ステップ数)",
    "tooltip": "プレビュー画像をNステップごとに生成します。バッチ数で割り切れる必要があります。"
  },
  "Save Settings": {
    "key": "設定を保存",
    "tooltip": "現在のトレーニングパラメータをモデルの設定ファイルに保存します。"
  },
  "Save Weights": {
    "key": "重みを保存",
    "tooltip": "学習中の保存のために、保存セクションで指定されたように重み/チェックポイント/スナップショットを保存する。"
  },
  "Save and Test Webhook": {
    "key": "Webフォークの保存とテスト",
    "tooltip": "現在入力されているWebhookのURLを保存し、テストメッセージを送信します。"
  },
  "Save separate diffusers snapshots when saving during training.": {
    "key": "トレーニング中、ディフューザの重みのスナップショットを個別に保存する。",
    "tooltip": "有効にすると、指定したエポック間隔ごとにディフューザーの重みのスナップショットが一つ保存されます。これはHDDの容量を(非常に) 多く使いますが、オプティマイザーの状態も含めて学習を再開することができます。"
  },
  "Save separate diffusers snapshots when training completes.": {
    "key": "トレーニング完了時に、ディフューザーのスナップショットを別々に保存する。",
    "tooltip": "有効にすると、トレーニング完了時にディフューザーの重みのスナップショットが一つ保存されます。これはHDDの容量をより多く使いますが、オプティマイザーの状態も含めて学習を再開することができます。"
  },
  "Save separate diffusers snapshots when training is cancelled.": {
    "key": "トレーニングのキャンセル時にディフューザーのスナップショットを個別に保存します。",
    "tooltip": "有効にすると、トレーニングキャンセル時にディフューザーの重みのスナップショットが一つ保存されます。これはHDDの容量をより多く使いますが、オプティマイザーの状態も含めて学習を再開することができます。"
  },
  "Save EMA Weights to Generated Models": {
    "key": "EMA Weightを生成されたモデルに保存",
    "tooltip": "もしモデルがEMAの重みから抽出されたり学習されたりした場合、これらはモデルに別々に追加されて、後で学習に使えるようになります。"
  },
  "Scale Position": {
    "key": "スケールの位置",
    "tooltip": "「最終的な」学習率が達成されるべきトレーニングのパーセント。 100エポックでトレーニングを行い、これが0.25に設定されている場合、最終的なLRは25エポックに達します。"
  },
  "Scheduler": {
    "key": "スケジューラー",
    "tooltip": "使用するモデルスケジューラ。2.0 以前のモデルにのみ適用されます。"
  },
  "Set Gradients to None When Zeroing": {
    "key": "勾配をゼロにするときにNoneにする",
    "tooltip": "逆伝播を行うとき、勾配は新しい空のテンソルを作る代わりにNoneに設定されます。これによりVRAMが若干改善されます。"
  },
  "Shuffle After Epoch": {
    "key": "エポック後シャッフル",
    "tooltip": "有効にすると、最初のエポックの後にデータセットをシャッフルします。テキストエンコーダのトレーニングと潜在キャッシュを有効にします(より多くVRAMを使用します)。"
  },
  "Shuffle Tags": {
    "key": "タグをシャッフル",
    "tooltip": "有効にすると、最初の「,」の後のタグがランダムに並べ替えられます。トレーニングが向上する可能性があります。"
  },
  "Source Checkpoint": {
    "key": "ソースのチェックポイント",
    "tooltip": "トレーニングのために抽出するソースチェックポイントです。"
  },
  "Step Ratio of Text Encoder Training": {
    "key": "テキストエンコーダトレーニングのステップ比率",
    "tooltip": "テキストエンコーダを学習させるための1画像あたりのステップ数(エポック) です。50%のエポックに対して0.5を設定してください。"
  },
  "Strict Tokens": {
    "key": "厳密なトークン",
    "tooltip": "次の文字 [,;...!] で区切られたインスタンスプロンプトを解析し、トークナイザーを使用する際にトークンが分割されるのを防ぎます。多くのタグで区切られたプロンプトがある場合に便利です。"
  },
  "Total Number of Class/Reg Images": {
    "key": "クラス/Reg 画像の合計数",
    "tooltip": "使用する分類/正規化画像の合計数。画像が存在しない場合は生成されます。先行保存を無効にする場合は0に設定してください。"
  },
  "Train Imagic Only": {
    "key": "画像のみでトレーニング",
    "tooltip": "Full Dreamboothの代わりにImagicをトレーニングに使用します。単一の画像でトレーニングするのに便利です。"
  },
  "Train Text Encoder": {
    "key": "テキストエンコーダを訓練する",
    "tooltip": "これを有効にすると、より良い結果と編集性が得られますが、より多くのVRAMを消費します。"
  },
  "Train": {
    "key": "学習",
    "tooltip": "トレーニングを開始"
  },
  "Training Steps Per Image (Epochs)": {
    "key": "イメージごとのトレーニングステップ (エポック)",
    "tooltip": "これは、各インスタンス画像に対して実行されるトレーニングステップの総数である。"
  },
  "Training Wizard (Object/Style)": {
    "key": "トレーニングウィザード (オブジェクト/スタイル)",
    "tooltip": "インスタンス画像の数に基づいて、人間以外を主体としたトレーニングパラメータを計算し、学習率を設定します。Prior-Preservation（事前分布の保存）を無効にします。"
  },
  "Training Wizard (Person)": {
    "key": "トレーニングウィザード (人)",
    "tooltip": "インスタンス画像の数に基づいて、人間を主体としたトレーニングパラメータを計算し、学習率を設定します。Prior-Preservation（事前分布の保存）を有効にします。"
  },
  "Unfreeze Model": {
    "key": "モデルを凍結解除",
    "tooltip": "凍結した（訓練対象から排除した）モデルのレイヤーを解凍し訓練対象とすることで、より良いトレーニングが可能になります。ただし、VRAMの使用量が増加する可能性が高くなります。"
  },
  "Use 8bit Adam": {
    "key": "8bit Adam を使用",
    "tooltip": "これを有効にするとVRAMが保存されます。"
  },
  "Use CPU Only (SLOW)": {
    "key": "CPUのみを使用 (低速)",
    "tooltip": "非常に遅い処理になると予想されますが、8GB未満のGPUでも機能します。"
  },
  "Use Concepts List": {
    "key": "コンセプトリストを使用",
    "tooltip": "JSONファイルや文字列から複数の概念を学習させる。"
  },
  "Use EMA": {
    "key": "EMAを使用",
    "tooltip": "これを有効にすると、より良い結果と編集性が得られますが、より多くのVRAMを消費します。"
  },
  "Use EMA Weights for Inference": {
    "key": "推論にEMA（指数移動平均）のウェイトを使用する",
    "tooltip": "これを有効にすると、EMAユニットの重みが「正常」モデルの重みとして保存され、通常のユニットの重みを無視します。"
  },
  "Use Epoch Values for Save Frequency": {
    "key": "頻度の保存にエポック値を使用する",
    "tooltip": "有効にすると、以下の保存頻度はエポック数に基づきます。無効にすると、頻度はトレーニングステップ数に基づきます。"
  },
  "Use LORA": {
    "key": "LORAを使用",
    "tooltip": "Text-to-Image DiffusionモデルのFine-tuningに、低ランクのAdaptationを使用します。VRAMの使用量を少なくし、full checkpointファイルではなく.ptファイルを保存します。"
  },
  "Use Lifetime Epochs When Saving": {
    "key": "保存時に有効中のエポックを使用する",
    "tooltip": "チェックを入れると、ライフタイムエポックを使用してプレビュー画像とチェックポイントを保存します。現在のトレーニングエポックではありません。"
  },
  "Use Lifetime Steps When Saving": {
    "key": "保存時にライフタイムステップを使用する",
    "tooltip": "When checked, will save preview images and checkpoints using lifetime steps, versus current training steps."
  }
}
